# Projeto AVD - AnÃ¡lise e VisualizaÃ§Ã£o de Dados MeteorolÃ³gicos

## ğŸ“‹ InformaÃ§Ãµes do Projeto

**Disciplina:** AnÃ¡lise e VisualizaÃ§Ã£o de Dados (AVD)  
**InstituiÃ§Ã£o:** CESAR SCHOOL  
**Projeto:** Pipeline completo de BI para anÃ¡lise de dados meteorolÃ³gicos do INMET

## ğŸ‘¥ Membros do Grupo

*Adicione os nomes e GitHub dos membros do grupo aqui*

## ğŸ¯ Objetivo

Desenvolver um pipeline completo de Business Intelligence (BI) para coleta, tratamento, integraÃ§Ã£o e visualizaÃ§Ã£o de dados meteorolÃ³gicos do INMET, utilizando uma arquitetura containerizada com Docker.

## ğŸ—ï¸ Arquitetura

O projeto utiliza uma arquitetura em microserviÃ§os containerizados:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI â”‚â”€â”€â”€â”€â–¶â”‚  MinIO  â”‚â”€â”€â”€â”€â–¶â”‚PostgreSQLâ”‚
â”‚ (8000)  â”‚     â”‚(9000)   â”‚     â”‚  (5432)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚            â”‚            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Jupyter â”‚  â”‚ MLFlow  â”‚  â”‚ Trendz  â”‚
    â”‚ (8880)  â”‚  â”‚ (5000)  â”‚  â”‚ (8888)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes

1. **FastAPI (porta 8000)**: API para ingestÃ£o de dados
   - `/fetch_inmet`: Baixa dados do INMET
   - `/upload`: Recebe arquivos CSV
   - `/store`: Armazena dados no MinIO

2. **MinIO (portas 9000/9090)**: Armazenamento S3-compatible
   - Bucket `raw/`: Dados brutos
   - Bucket `processed/`: Dados tratados
   - Bucket `models/`: Modelos ML

3. **PostgreSQL (porta 5432)**: Banco de dados estruturado
   - Tabela `weather_hourly`: Dados horÃ¡rios
   - Tabela `weather_daily`: AgregaÃ§Ãµes diÃ¡rias
   - Tabela `ml_models`: Metadados de modelos

4. **JupyterLab (porta 8880)**: AnÃ¡lise e modelagem
   - Notebooks de EDA
   - Processamento e limpeza
   - Feature engineering
   - Treinamento de modelos

5. **MLFlow (porta 5000)**: Versionamento de modelos
   - Tracking de experimentos
   - Registro de mÃ©tricas e parÃ¢metros
   - Armazenamento de artefatos

6. **Trendz Analytics (porta 8888)**: Dashboards interativos

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Docker e Docker Compose instalados
- Git

### Passo a Passo

1. **Clone o repositÃ³rio** (se ainda nÃ£o tiver):
```bash
git clone <url-do-repositorio>
cd classificacao_conforto_termico
```

2. **Inicie todos os serviÃ§os**:
```bash
docker-compose up -d
```

3. **Aguarde os serviÃ§os iniciarem** (pode levar alguns minutos na primeira execuÃ§Ã£o):
```bash
docker-compose ps
```

4. **Acesse os serviÃ§os**:

   - **FastAPI**: http://localhost:8000
     - DocumentaÃ§Ã£o: http://localhost:8000/docs
   
   - **MinIO Console**: http://localhost:9090
     - UsuÃ¡rio: `minioadmin`
     - Senha: `minioadmin`
   
   - **JupyterLab**: http://localhost:8880
     - Sem senha (desenvolvimento)
   
   - **MLFlow**: http://localhost:5000
   
   - **Trendz**: http://localhost:8888
   
   - **PostgreSQL**: `localhost:5432`
     - UsuÃ¡rio: `postgres`
     - Senha: `postgres`
     - Database: `weather_db`

### Upload de Dados Iniciais

Se vocÃª jÃ¡ tem dados CSV locais, pode fazer upload via FastAPI:

```bash
# Via curl
curl -X POST "http://localhost:8000/upload" \
  -H "accept: application/json" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@data/dados_2020/dados_recife_2020.CSV"

# Ou via interface web em http://localhost:8000/docs
```

### Processamento de Dados

1. Acesse o JupyterLab: http://localhost:8880
2. Abra o notebook `notebooks/02_processamento_limpeza.py`
3. Execute o script para processar os dados do bucket `raw/` e salvar em `processed/` e PostgreSQL

### Treinamento de Modelos

1. No JupyterLab, abra `notebooks/03_modelagem_conforto_termico.ipynb`
2. Execute as cÃ©lulas para treinar o modelo
3. O modelo serÃ¡ versionado automaticamente no MLFlow

## ğŸ“Š Dados

### Cidades Monitoradas (Pernambuco)

- Arco Verde
- CabrobÃ³
- Caruaru
- Floresta
- Garanhuns
- Ibimirim
- Ouricuri
- Palmares
- Petrolina
- Recife
- Salgueiro
- Serra Talhada
- Surubim

### PerÃ­odo

Dados de 2020 a 2024 (5 anos)

### VariÃ¡veis MeteorolÃ³gicas

- Temperatura (Â°C)
- Umidade relativa (%)
- PressÃ£o atmosfÃ©rica (mB)
- DireÃ§Ã£o do vento (graus)
- Velocidade do vento (m/s)
- RadiaÃ§Ã£o solar (Kj/mÂ²)
- PrecipitaÃ§Ã£o (mm)

## ğŸ“ Estrutura do Projeto

```
classificacao_conforto_termico/
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o dos serviÃ§os
â”œâ”€â”€ data/                       # Dados CSV locais
â”‚   â”œâ”€â”€ dados_2020/
â”‚   â”œâ”€â”€ dados_2021/
â”‚   â”œâ”€â”€ dados_2022/
â”‚   â”œâ”€â”€ dados_2023/
â”‚   â”œâ”€â”€ dados_2024/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ fastapi/                    # API de ingestÃ£o
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ jupyterlab/                 # Ambiente Jupyter
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ mlflow/                     # ConfiguraÃ§Ã£o MLFlow
â”œâ”€â”€ notebooks/                  # Notebooks de anÃ¡lise
â”‚   â”œâ”€â”€ 01_eda_limpeza.ipynb
â”‚   â”œâ”€â”€ 02_processamento_limpeza.py
â”‚   â”œâ”€â”€ 03_modelagem_conforto_termico.ipynb
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ sql_scripts/                # Scripts SQL
â”‚   â””â”€â”€ 01_create_tables.sql
â”œâ”€â”€ trendz/                     # ConfiguraÃ§Ã£o Trendz
â”œâ”€â”€ reports/                    # RelatÃ³rios gerados
â”œâ”€â”€ data_utils.py              # UtilitÃ¡rios de dados
â”œâ”€â”€ claude.md                  # DocumentaÃ§Ã£o do projeto
â””â”€â”€ README.md                  # Este arquivo
```

## ğŸ”§ Comandos Ãšteis

### Docker Compose

```bash
# Iniciar serviÃ§os
docker-compose up -d

# Parar serviÃ§os
docker-compose down

# Ver logs
docker-compose logs -f [servico]

# Reconstruir imagens
docker-compose build

# Reiniciar um serviÃ§o especÃ­fico
docker-compose restart [servico]
```

### MinIO

```bash
# Listar buckets
docker exec minio mc ls myminio/

# Listar arquivos em um bucket
docker exec minio mc ls myminio/raw/

# Baixar arquivo
docker exec minio mc cp myminio/raw/arquivo.csv /tmp/
```

### PostgreSQL

```bash
# Conectar ao banco
docker exec -it postgres psql -U postgres -d weather_db

# Executar query
docker exec postgres psql -U postgres -d weather_db -c "SELECT COUNT(*) FROM weather_hourly;"
```

## ğŸ“ˆ Modelos Implementados

O projeto suporta os seguintes problemas/modelos:

1. Agrupar padrÃµes climÃ¡ticos (Clustering)
2. Classificar dias chuvosos vs ensolarados (ClassificaÃ§Ã£o binÃ¡ria)
3. Prever temperatura horÃ¡ria (RegressÃ£o temporal)
4. Agrupar estaÃ§Ãµes por perfil (Clustering)
5. **Classificar conforto tÃ©rmico** (ClassificaÃ§Ã£o multiclasse) - *Implementado*
6. Prever umidade relativa (RegressÃ£o)
7. Agrupar padrÃµes de vento (Clustering)
8. Classificar intensidade da chuva (ClassificaÃ§Ã£o multiclasse)
9. Agrupar condiÃ§Ãµes extremas (Clustering)
10. Prever sensaÃ§Ã£o tÃ©rmica (RegressÃ£o)

## ğŸ§ª Testes

Para testar a API FastAPI:

```bash
# Health check
curl http://localhost:8000/health

# Listar arquivos no MinIO
curl http://localhost:8000/list_files?bucket=raw

# Upload de arquivo
curl -X POST "http://localhost:8000/upload" \
  -F "file=@caminho/para/arquivo.csv"
```

## ğŸ“ Notas de Desenvolvimento

- Os dados sÃ£o armazenados em volumes Docker para persistÃªncia
- As credenciais padrÃ£o sÃ£o para desenvolvimento apenas
- Em produÃ§Ã£o, altere todas as senhas e use variÃ¡veis de ambiente
- O MinIO Ã© configurado automaticamente com os buckets necessÃ¡rios

## ğŸ› Troubleshooting

### ServiÃ§os nÃ£o iniciam

```bash
# Verificar logs
docker-compose logs

# Verificar portas em uso
lsof -i :8000
lsof -i :9000
```

### Erro de conexÃ£o com MinIO

- Verifique se o MinIO estÃ¡ saudÃ¡vel: `docker-compose ps minio`
- Aguarde alguns segundos apÃ³s iniciar o MinIO

### Erro de conexÃ£o com PostgreSQL

- Verifique se o PostgreSQL estÃ¡ pronto: `docker-compose ps postgres`
- Aguarde a inicializaÃ§Ã£o completa do banco

## ğŸ“„ LicenÃ§a

Ver arquivo LICENSE

## ğŸ“š ReferÃªncias

- [INMET](https://portal.inmet.gov.br/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [MLFlow Documentation](https://www.mlflow.org/docs/latest/index.html)
- [MinIO Documentation](https://min.io/docs/)
- [Trendz Analytics](https://trendz-iot.github.io/)

